{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aissahm/FedSeleKDistill/blob/main/FedSeleKDistill.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-lwch9qvEPg"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "#given the dataset X, Y, the object with indexes for every client, returns the dataset of client identified with its client_id\n",
        "def returnClientDataset(client_id, clients_data_obj, x, y):\n",
        "  dataset_indexes = np.array(clients_data_obj[client_id][\"indexes\"])\n",
        "  return [x[dataset_indexes], y[dataset_indexes]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SKGoh_MwHIv",
        "outputId": "24c7f4d7-7207-4a7f-81f4-c8de4474f48c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "number_clients = 30\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "clients_datasets_obj_filename = \"/content/MNIST_30_clients_70percent_main_class.pickle\"\n",
        "\n",
        "clients_datasets_obj = pickle.load( open(clients_datasets_obj_filename, \"rb\" ) )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clients_datasets_obj[0]"
      ],
      "metadata": {
        "id": "BDmCcrfDj5ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1X64OtEpwlza",
        "outputId": "fddac406-ad5a-4c27-d83b-ae9c3ea534e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# Load the data and split it between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xJ88hB_wVjr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhW6FjcEwZJq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, losses, optimizers\n",
        "import random\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def knowledge_distillation_loss(y_true, y_pred):\n",
        "            y_true = tf.convert_to_tensor(y_true, dtype=tf.float32)\n",
        "\n",
        "            # Ensure that y_pred has the same shape as soft targets\n",
        "            y_pred = tf.convert_to_tensor(y_pred, dtype=tf.float32)\n",
        "\n",
        "            loss_ce = losses.categorical_crossentropy(y_true, y_pred, from_logits=False)\n",
        "            return loss_ce\n",
        "\n",
        "def returnInitialGlobalModel():\n",
        "  model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "  #model.summary()\n",
        "  model.compile(loss=knowledge_distillation_loss, optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "  return model\n",
        "\n",
        "#returns a copy of the global model to client\n",
        "def returnCopyGlobalModelToClient(globalmodel):\n",
        "  clientmodel = returnInitialGlobalModel()\n",
        "  clientmodel.set_weights(globalmodel.get_weights())\n",
        "  return clientmodel\n",
        "\n",
        "#Given the weights after training and initial weights, returns the gradient from entire training\n",
        "def computeClientGradientNoCompression(modelNotTrained, modelTrained):\n",
        "  gradient = []\n",
        "  notTrainedWeight = modelNotTrained.get_weights()\n",
        "  i = 0\n",
        "  for weight in modelTrained.get_weights():\n",
        "    gradient.append( notTrainedWeight[i] - weight )\n",
        "    i += 1\n",
        "  return gradient\n",
        "\n",
        "#add the client gradient to the global model\n",
        "def addGradientNoCompression(modelNotTrained, gradient, client_weight):\n",
        "  newWeight = []\n",
        "  i = 0\n",
        "  notTrainedWeight = modelNotTrained.get_weights()\n",
        "  for weight in modelNotTrained.get_weights():\n",
        "    newWeight.append( weight - (gradient[i] * client_weight) )\n",
        "    i += 1\n",
        "  modelNotTrained.set_weights(newWeight)\n",
        "\n",
        "#Generate a random list of clients considered of length num_clients_considered\n",
        "def returnRandomSelectedClientsIDsList():\n",
        "  return random.sample(range(0, num_clients), num_clients_considered)\n",
        "\n",
        "#return random clients\n",
        "def returnRandomParticipatingClients(num_clients, num_participating_clients):\n",
        "  return random.sample(range(0, num_clients), num_participating_clients)\n",
        "\n",
        "#function that returns the accuracy score of the model on  the data\n",
        "def evaluateGlobalModel(client_model, x, y):\n",
        "  return client_model.evaluate(x, y, verbose=0)\n",
        "\n",
        "def returnClientGradientAsVector(client_gradient):\n",
        "  weights = []\n",
        "  for weight in client_gradient:\n",
        "      weight = weight.reshape(weight.size)\n",
        "      weights.extend( weight)\n",
        "  return np.array(weights)\n",
        "\n",
        "def returnClientLambdaValueKD(i, client_accuracy, server_side_accuracy):\n",
        "  return 1 - client_accuracy\n",
        "\n",
        "#function that returns the evaluation of the global model on the selected clients\n",
        "def returnWorstLossesAmongChosenClients(classifierModel, chosenClients, datasetObject):\n",
        "\n",
        "  clients_accuracy_list = []\n",
        "  j = 0\n",
        "\n",
        "  #evaluate the classifier on each random client's data\n",
        "  while j < len(chosenClients):\n",
        "\n",
        "    client_id = chosenClients[j]\n",
        "    client_x, client_y = returnClientDataset(client_id, datasetObject, x_train, y_train)\n",
        "    client_evaluation_score = evaluateGlobalModel(classifierModel, client_x, client_y)\n",
        "    #print(client_evaluation_score)\n",
        "    clients_accuracy_list.append({\"clientID\": client_id, \"accuracy\": client_evaluation_score[1]})\n",
        "\n",
        "    j+= 1\n",
        "\n",
        "  #order the losses from worst to best\n",
        "  clients_accuracy_list.sort(key=lambda x: x[\"accuracy\"], reverse=False)\n",
        "\n",
        "  return clients_accuracy_list\n",
        "\n",
        "def returnAccuracyScoreForClient(clientID, clients_accuracy_list):\n",
        "  for client_accuracy_elem in clients_accuracy_list:\n",
        "    if client_accuracy_elem[\"client_id\"] == clientID:\n",
        "      return client_accuracy_elem[\"accuracy\"]\n",
        "  print('accuracy not found for' , clientID )\n",
        "  return -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f13rPRjCyU40"
      },
      "outputs": [],
      "source": [
        "#main code running on server side\n",
        "def runTrainingNoCompression(classifierModel, accuracyScoreTarget, clientsDatasetObject, lambda_val):\n",
        "\n",
        "  #We first evaluate the global model\n",
        "  globalAccuracy = evaluateGlobalModel(classifierModel, central_server_data_x, central_server_data_y_true)\n",
        "\n",
        "  print(\"Starting\")\n",
        "  print(\"dataset \", clients_datasets_obj_filename)\n",
        "  print(\"Before training global model accuracy =\", globalAccuracy)\n",
        "  print()\n",
        "\n",
        "  i = 0\n",
        "  accuracy_score = 0\n",
        "  per_round_global_model_accuracy = []\n",
        "  per_round_global_model_loss = []\n",
        "  convergence_reached_at_round = 0\n",
        "\n",
        "  per_round_global_model_accuracy.append(globalAccuracy[1])\n",
        "  per_round_global_model_loss.append(globalAccuracy[0])\n",
        "\n",
        "  while i < max_num_rounds:\n",
        "\n",
        "      #print(\"Round \", i + 1, \" / Max rounds \", max_num_rounds)\n",
        "\n",
        "      #select random clients\n",
        "      random_clients = returnRandomSelectedClientsIDsList()\n",
        "\n",
        "      #return the list of clients with loss value from worst to best\n",
        "      pretraining_loss_values_obj = returnWorstLossesAmongChosenClients(classifierModel, random_clients, clientsDatasetObject)\n",
        "\n",
        "      print(\"Model evaluation on clients : \", pretraining_loss_values_obj)\n",
        "      #print(\"Selected clients :\", pretraining_loss_values_obj[:num_clients_selected])\n",
        "\n",
        "      selected_clients_grad_list = []\n",
        "\n",
        "      round_lambda_values = []\n",
        "\n",
        "      ##################\n",
        "      #At client\n",
        "      ##################\n",
        "\n",
        "      #training classifier on each client\n",
        "      for selected_client in pretraining_loss_values_obj[:num_clients_selected]:\n",
        "\n",
        "          client_id = selected_client[\"clientID\"]\n",
        "\n",
        "          #training the global model on client's local data\n",
        "          client_x, client_y = returnClientDataset(client_id, clientsDatasetObject, x_train, y_train)\n",
        "\n",
        "\n",
        "          #####KD\n",
        "          ###BEGINING KD\n",
        "\n",
        "          # Build the teacher and student models\n",
        "          teacher_model = returnCopyGlobalModelToClient(classifierModel)\n",
        "          student_model = returnCopyGlobalModelToClient(classifierModel)\n",
        "\n",
        "          # Use teacher model to generate \"soft targets\" for the student\n",
        "          soft_target_train = teacher_model.predict(client_x)\n",
        "\n",
        "          def student_knowledge_distillation_loss(y_true, y_pred):\n",
        "            y_true = tf.convert_to_tensor(y_true, dtype=tf.float32)\n",
        "\n",
        "            # Ensure that y_pred has the same shape as soft targets\n",
        "            y_soft = tf.convert_to_tensor(soft_target_train, dtype=tf.float32)\n",
        "            y_pred = tf.convert_to_tensor(y_pred, dtype=tf.float32)\n",
        "\n",
        "            loss_ce = losses.categorical_crossentropy(y_true, y_pred, from_logits=False)\n",
        "\n",
        "            loss_kd = tf.keras.losses.KLD(y_soft, tf.nn.softmax(y_pred / temperature))\n",
        "\n",
        "            return (1- lambda_val)*loss_ce + lambda_val * loss_kd  # Adjust the weight for the distillation loss as needed\n",
        "\n",
        "\n",
        "          #set student weights to central server weights and recompile\n",
        "          student_model.compile(loss=student_knowledge_distillation_loss, optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "          student_model.set_weights(teacher_model.get_weights())\n",
        "\n",
        "          #training model on client data\n",
        "          student_model.fit(client_x, client_y, epochs=num_iterations_per_round,\n",
        "                              validation_split = validation_size ,verbose=0,  batch_size=batch_size)\n",
        "\n",
        "\n",
        "          #getting the gradient from the client\n",
        "          client_gradient = computeClientGradientNoCompression(classifierModel, student_model)\n",
        "\n",
        "          #storing the gradients to be sent to central server\n",
        "          selected_clients_grad_list.append( {\"client_id\": client_id, \"clientgradient\": client_gradient} )\n",
        "\n",
        "\n",
        "      ##################\n",
        "      #At central server\n",
        "      ##################\n",
        "\n",
        "      #updating the global model weights\n",
        "      for client_gradient in selected_clients_grad_list:\n",
        "\n",
        "          client_id = client_gradient[\"client_id\"]\n",
        "          client_x, client_y = returnClientDataset(client_id, clientsDatasetObject, x_train, y_train)\n",
        "          client_weight = client_y.shape[0] / y_train.shape[0]\n",
        "\n",
        "          addGradientNoCompression(classifierModel, client_gradient[\"clientgradient\"], client_weight)\n",
        "\n",
        "\n",
        "      #evaluating the global model on data contained in central server\n",
        "      globalModelEvaluation = evaluateGlobalModel(classifierModel, central_server_data_x, central_server_data_y_true)\n",
        "\n",
        "      globalAccuracy = globalModelEvaluation[1]\n",
        "      per_round_global_model_accuracy.append(globalAccuracy)\n",
        "      per_round_global_model_loss.append(globalModelEvaluation[0])\n",
        "\n",
        "      print(\"Round \", i,  \", global model accuracy score = \", globalAccuracy)\n",
        "      print()\n",
        "\n",
        "      i += 1\n",
        "\n",
        "\n",
        "  #plot the results\n",
        "  print(\"Number of clients :\", num_clients)\n",
        "  print(\"Number of clients participating per round :\", num_clients_considered)\n",
        "  print(\"Number of clients training the model per round : \", num_clients_selected)\n",
        "  print(\"Number of iterations per client per round : \", num_iterations_per_round)\n",
        "  print(\"Number of rounds until convergence : \", convergence_reached_at_round)\n",
        "\n",
        "  #accuracy for each client dataset\n",
        "  clients_final_accuracy_list = []\n",
        "\n",
        "  for i in range(0, num_clients):\n",
        "    #get client dataset\n",
        "    client_x, client_y = returnClientDataset(i, clientsDatasetObject, x_train, y_train)\n",
        "    client_score = evaluateGlobalModel(classifierModel, client_x, client_y)\n",
        "    clients_final_accuracy_list.append( client_score[1])\n",
        "  print(\"clients_final_accuracy_list\", clients_final_accuracy_list)\n",
        "\n",
        "  print (per_round_global_model_accuracy)\n",
        "  print (per_round_global_model_loss)\n",
        "\n",
        "  plt.plot(per_round_global_model_accuracy)\n",
        "  plt.ylabel('Accuracy per round')\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(per_round_global_model_loss)\n",
        "  plt.ylabel('Loss per round')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Setting the experiment parameters**"
      ],
      "metadata": {
        "id": "qzmIHSZbC8In"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37gDZrIDy5I9"
      },
      "outputs": [],
      "source": [
        "central_server_data_x, central_server_data_y_true = x_test, y_test\n",
        "\n",
        "num_iterations_per_round = 4\n",
        "validation_size = 0.15\n",
        "\n",
        "batch_size = 1\n",
        "temperature = 5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_global_model = returnInitialGlobalModel()\n",
        "\n",
        "runTrainingNoCompression(initial_global_model, accuracy_score_target , clients_datasets_obj)"
      ],
      "metadata": {
        "id": "J_0808tFCxgO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}